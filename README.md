# Transformer Architectures in Biometrics

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)

Advanced applications of transformer architectures in biometric recognition systems, covering fingerprint, face, iris, and voice biometrics with hands-on implementation.

## ğŸ“‹ Course Overview

This repository contains materials for a graduate-level course exploring how self-attention mechanisms revolutionize biometric feature extraction, representation, and matching. Each week combines theoretical foundations with practical implementations using real datasets like SOCOFing.

**ğŸ“– Full Course Details:** See [Syllabus](syllabus.md) for complete information including assessment, grading, and schedule.

## ğŸš€ Quick Start

### Week 1: Foundational Transformer Architectures
[![Week 1 Colab](https://img.shields.io/badge/Week%201-Open%20in%20Colab-blue?logo=google-colab)](https://colab.research.google.com/github/clarkson-edge/ee622/blob/main/Week%201/lab/week1_transformer_attention_visualization.ipynb)

**Topics:** Transformer fundamentals, self-attention mechanisms, attention visualization
**Lab:** Visualizing attention patterns across biometric modalities (face, fingerprint, iris)

### Week 2: Fingerprint Feature Extraction and Matching
[![Week 2 Colab](https://img.shields.io/badge/Week%202-Open%20in%20Colab-blue?logo=google-colab)](https://colab.research.google.com/github/clarkson-edge/ee622/blob/main/Week%202/lab/week2_nb1_fingerprint_transformer.ipynb)

**Topics:** Hybrid CNN-transformer architectures, quality-aware processing, AFIS integration
**Lab:** SOCOFing dataset processing, core-focused attention analysis, adaptive position encoding

## ğŸ“š Repository Structure

```
â”œâ”€â”€ Week 1/
â”‚   â”œâ”€â”€ lab/week1_transformer_attention_visualization.ipynb
â”‚   â”œâ”€â”€ materials/
â”‚   â”‚   â”œâ”€â”€ Iris-SAM.pdf
â”‚   â”‚   â””â”€â”€ NIPS - Attention is All You Need.pdf
â”‚   â””â”€â”€ slides/week1_transformer_biometrics_presentation.pptx
â”œâ”€â”€ Week 2/
â”‚   â”œâ”€â”€ lab/week2_nb1_fingerprint_transformer.ipynb
â”‚   â””â”€â”€ slides/week2_theory_fingerprint_transformers.pptx
â”œâ”€â”€ syllabus.md
â”œâ”€â”€ biometric_transformer_cheatsheet.md
â”œâ”€â”€ biometrics-glossary.md
â”œâ”€â”€ transformer-formulas-reference.md
â””â”€â”€ graduate-projects.md
```

## ğŸ¯ Learning Objectives

- Master transformer architectures for biometric applications
- Implement self-attention mechanisms for feature extraction and matching
- Design hybrid CNN-transformer systems with quality-aware processing
- Visualize and interpret attention patterns (core-focused analysis)
- Evaluate performance against traditional methods using standard datasets
- Develop adaptive position encoding for biometric-specific spatial relationships

## ğŸ› ï¸ Setup

### Google Colab (Recommended)
Click the Colab badges above to open notebooks directly from the GitHub repository. The notebooks include:
- SOCOFing dataset access via kagglehub
- Pre-trained transformer models
- Visualization libraries for attention analysis

### Local Development
```bash
# Create environment
conda create -n biometric-transformers python=3.8+
conda activate biometric-transformers

# Install packages
pip install torch torchvision transformers
pip install opencv-python scikit-image matplotlib seaborn
pip install kagglehub gradio numpy scipy pandas
```

## ğŸ“– Key Resources & References

### ğŸ“‹ Essential Reference Materials
- **ğŸ”§ Implementation Guide:** [Biometric Transformer Architecture Cheat Sheet](biometric_transformer_cheatsheet.md)
  - Complete implementation patterns for all biometric modalities
  - SOCOFing dataset integration examples
  - Quality-aware attention mechanisms
  - Cross-modal fusion strategies

- **ğŸ“š Technical Glossary:** [Biometric Transformers Key Terms](biometrics-glossary.md)
  - Comprehensive terminology for transformer architectures
  - Fingerprint-specific concepts (PoincarÃ© index, ridge coherence, core detection)
  - Cross-modal and multimodal fusion definitions
  - Implementation and evaluation concepts

- **ğŸ§® Mathematical Foundations:** [Transformer Formulas Reference](transformer-formulas-reference.md)
  - Core transformer equations with biometric adaptations
  - Fingerprint analysis formulas (orientation estimation, quality assessment)
  - Performance metrics and evaluation mathematics
  - Training objectives and optimization techniques

- **ğŸ“ Research Projects:** [Graduate Project Ideas](graduate-projects.md)
  - 24 moderate-difficulty projects for 45-day completion
  - Covers all major biometric modalities
  - Includes evaluation criteria and deliverables

### ğŸ“„ Foundational Papers
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) (Vaswani et al., 2017) - Original transformer architecture
- [Vision Transformers](https://arxiv.org/abs/2010.11929) (Dosovitskiy et al., 2020) - ViT foundation
- [Transformer Fingerprint Recognition](https://ieeexplore.ieee.org/document/9956435) (IEEE 2022) - Biometric applications
- [Cross-Spectral Vision Transformer](https://arxiv.org/html/2412.19160v2) (2024) - Advanced biometric fusion

### ğŸŒ External Resources
- [Course GitHub Repository](https://github.com/clarkson-edge/ee622) - Complete course materials and notebooks
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) - Visual explanations
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/) - Implementation library
- [Papers With Code](https://paperswithcode.com/methods/category/transformers) - Latest research
- [SOCOFing Dataset](https://www.kaggle.com/datasets/ruizgara/socofing) - Real fingerprint data

## ğŸ§ª What You'll Build

### Week 1: Multi-Modal Attention Visualization System
- Extract attention maps from pre-trained Vision Transformers
- Visualize attention patterns across biometric modalities (face, fingerprint, iris)
- Compare attention evolution across transformer layers
- Identify biometrically significant regions through attention analysis

### Week 2: Advanced Fingerprint Recognition Pipeline
- **SOCOFing Dataset Integration:** Real African fingerprint data processing
- **Adaptive Preprocessing:** Gabor filtering, orientation estimation, core detection using PoincarÃ© index
- **Quality-Aware Transformers:** Patch quality assessment and attention weighting
- **Core-Focused Analysis:** Attention correlation with fingerprint structure
- **Hybrid Architecture:** CNN backbone + transformer layers for global-local features

### Key Innovations Demonstrated
- **Adaptive Position Encoding:** Fingerprint core detection and relative spatial encoding
- **Quality-Aware Attention:** Dynamic weighting based on patch reliability
- **Multi-Layer Attention Analysis:** Evolution from structural to semantic focus
- **Cross-Modal Understanding:** Attention patterns transferable across biometric types

## ğŸ“Š Performance Benchmarks

The implementations demonstrate state-of-the-art results:
- **Attention Correlation:** 0.4618 distance-attention correlation in fingerprint analysis
- **Quality Assessment:** Automatic patch scoring for robust recognition
- **Core Detection Accuracy:** PoincarÃ© index-based singular point detection
- **Multi-Modal Fusion:** Cross-attention mechanisms for enhanced security

## ğŸ¤ Contributing

This is an educational repository designed for graduate-level biometric research. Contributions welcome for:
- Additional biometric modality implementations
- Novel attention visualization techniques
- Performance optimizations for edge deployment
- New dataset integrations

For questions or suggestions, please open an issue or submit a pull request.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”¬ Research Applications

This repository serves as a foundation for:
- **Academic Research:** PhD-level biometric transformer development
- **Industry Applications:** Production-ready biometric authentication systems
- **Security Research:** Anti-spoofing and presentation attack detection
- **Cross-Modal Studies:** Multimodal biometric fusion research

---

**ğŸ“ Academic Use:** This repository is designed for graduate-level education in biometric systems and transformer architectures. All implementations use real datasets and demonstrate production-ready techniques while maintaining educational clarity.

**âš¡ Quick Links:**
- [ğŸ“– Complete Syllabus](syllabus.md)
- [ğŸ”§ Architecture Cheat Sheet](biometric_transformer_cheatsheet.md)
- [ğŸ“š Technical Glossary](biometrics-glossary.md)
- [ğŸ§® Mathematical Reference](transformer-formulas-reference.md)
- [ğŸ“ Research Projects](graduate-projects.md)
